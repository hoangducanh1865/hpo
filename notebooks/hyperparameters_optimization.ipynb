{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abdedc0",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization (HPO) - Complete Implementation\n",
    "\n",
    "This notebook demonstrates a complete HPO framework with multiple algorithms and models.\n",
    "\n",
    "## HPO Algorithms Implemented:\n",
    "\n",
    "1. **Random Search** - Baseline algorithm with random sampling\n",
    "2. **Bayesian Optimization** - Model-based optimization using:\n",
    "   - **Surrogate Model**: Gaussian Process with Matérn 5/2 kernel\n",
    "   - **Acquisition Function**: Expected Improvement (EI)\n",
    "   - **Optimization**: L-BFGS-B with 25 random restarts\n",
    "3. **Successive Halving (SH)** - Synchronous multi-fidelity optimization\n",
    "4. **ASHA** - Asynchronous Successive Halving Algorithm\n",
    "\n",
    "## Models Supported:\n",
    "\n",
    "| Model | Type | Hyperparameters | Description |\n",
    "|-------|------|----------------|-------------|\n",
    "| **SoftmaxRegression** | Linear | lr, batch_size | Simple baseline (~82-85% accuracy) |\n",
    "| **LeNet** | CNN | lr, batch_size | Best accuracy (~85-90%) |\n",
    "| **SGDClassifier** | Linear SVM | lr, batch_size, alpha, l1_ratio | Fast linear classifier with Elastic Net |\n",
    "| **SVMClassifier** | Kernel SVM | lr, batch_size, C, gamma | RBF kernel approximation via Random Fourier Features |\n",
    "\n",
    "## Dataset:\n",
    "- **FashionMNIST**: 60,000 training images (80% train, 20% validation), 10,000 test images\n",
    "- **Classes**: 10 fashion categories (T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot)\n",
    "\n",
    "## Key Features:\n",
    "- Modular design with abstract base classes (HPOSearcher, HPOScheduler)\n",
    "- Model-specific hyperparameter handling via `Utils.build_model(args, config)`\n",
    "- Progress tracking and visualization\n",
    "- Support for both single-fidelity (Random, BO) and multi-fidelity (SH, ASHA) algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370d007",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea20468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision tqdm matplotlib scipy numpy scikit-learn\n",
    "# Or use requirements.txt\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5804eb58",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8813020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479af6b",
   "metadata": {},
   "source": [
    "## Configuration and Argument Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Args:\n",
    "    \"\"\"Argument class for HPO experiments\"\"\"\n",
    "    def __init__(self):\n",
    "        self.model_name = \"softmax\"\n",
    "        self.num_epochs = 10\n",
    "        self.learning_rate = 0.1\n",
    "        self.batch_size = 256\n",
    "        self.num_outputs = 10\n",
    "        self.num_trials = 10\n",
    "        self.eta = 2  # Reduction factor for multi-fidelity\n",
    "        self.min_number_of_epochs = 5\n",
    "        self.max_number_of_epochs = 20\n",
    "        self.prefact = 1\n",
    "        # Model-specific hyperparameters\n",
    "        self.alpha = 0.0001  # SGD regularization\n",
    "        self.l1_ratio = 0.15  # SGD elastic net mixing\n",
    "        self.C = 1.0  # SVM penalty parameter\n",
    "        self.gamma = 0.001  # SVM RBF kernel coefficient\n",
    "\n",
    "print(f\"Using device: {Config.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28b6b8",
   "metadata": {},
   "source": [
    "## Model Definitions\n",
    "\n",
    "All models are implemented as PyTorch `nn.Module` with custom loss functions that include regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af538c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression(nn.Module):\n",
    "    \"\"\"Softmax Regression (Multinomial Logistic Regression) model.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_outputs: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(784, num_outputs)  # 28x28 → 784 input features\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "    def loss(self, Y_hat, Y, averaged=True):\n",
    "        Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n",
    "        Y = Y.reshape((-1,))\n",
    "        return F.cross_entropy(Y_hat, Y, reduction=\"mean\" if averaged else \"none\")\n",
    "\n",
    "\n",
    "def init_cnn(module):\n",
    "    \"\"\"Xavier initialization for CNN weights\"\"\"\n",
    "    if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    \"\"\"Classic LeNet CNN architecture for image classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "    def loss(self, Y_hat, Y, averaged=True):\n",
    "        Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n",
    "        Y = Y.reshape((-1,))\n",
    "        return F.cross_entropy(Y_hat, Y, reduction=\"mean\" if averaged else \"none\")\n",
    "    \n",
    "    def apply_init(self):\n",
    "        self.apply(init_cnn)\n",
    "\n",
    "\n",
    "class SGDClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    SGD Linear Classifier with Elastic Net regularization.\n",
    "    Implements hinge loss (linear SVM) with mixed L1/L2 penalty.\n",
    "    \n",
    "    Key hyperparameters:\n",
    "    - alpha: Regularization strength (higher = more regularization)\n",
    "    - l1_ratio: Elastic net mixing parameter\n",
    "        * 0.0 = pure L2 (Ridge)\n",
    "        * 1.0 = pure L1 (Lasso)\n",
    "        * 0.15 = balanced (default)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10, alpha=0.0001, l1_ratio=0.15):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "    def loss(self, Y_hat, Y, averaged=True):\n",
    "        \"\"\"Hinge loss (linear SVM) + Elastic Net regularization\"\"\"\n",
    "        Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n",
    "        Y = Y.reshape((-1,))\n",
    "        \n",
    "        # Multi-class hinge loss\n",
    "        hinge_loss = F.multi_margin_loss(Y_hat, Y, reduction=\"mean\" if averaged else \"none\")\n",
    "        \n",
    "        # Elastic Net: alpha * (l1_ratio * L1 + (1 - l1_ratio) * L2)\n",
    "        linear_layer = self.net[1]\n",
    "        l1_reg = torch.sum(torch.abs(linear_layer.weight))\n",
    "        l2_reg = torch.sum(linear_layer.weight ** 2)\n",
    "        elastic_net = self.alpha * (self.l1_ratio * l1_reg + (1 - self.l1_ratio) * 0.5 * l2_reg)\n",
    "        \n",
    "        return hinge_loss + elastic_net\n",
    "\n",
    "\n",
    "class SVMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    SVM with RBF kernel approximation via Random Fourier Features.\n",
    "    \n",
    "    Key hyperparameters:\n",
    "    - C: Penalty parameter (inverse regularization, higher = less regularization)\n",
    "    - gamma: RBF kernel coefficient (higher = more local decision boundary)\n",
    "    - n_components: Number of random features for kernel approximation\n",
    "    \n",
    "    The RBF kernel k(x, y) = exp(-gamma * ||x - y||^2) is approximated using\n",
    "    Random Fourier Features: cos(Xw + b) where w ~ N(0, 2*gamma*I)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10, C=1.0, gamma=0.001, n_components=100):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        self.n_components = n_components\n",
    "        \n",
    "        # Random Fourier Features for RBF kernel approximation\n",
    "        self.random_weights = nn.Parameter(\n",
    "            torch.randn(784, n_components) * torch.sqrt(torch.tensor(2 * gamma)),\n",
    "            requires_grad=False\n",
    "        )\n",
    "        self.random_offset = nn.Parameter(\n",
    "            torch.rand(n_components) * 2 * torch.pi,\n",
    "            requires_grad=False\n",
    "        )\n",
    "        \n",
    "        # Linear classifier on top of kernel features\n",
    "        self.classifier = nn.Linear(n_components, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = X.view(X.size(0), -1)  # Flatten\n",
    "        \n",
    "        # Random Fourier Features: cos(Xw + b)\n",
    "        projection = torch.matmul(X, self.random_weights) + self.random_offset\n",
    "        features = torch.cos(projection) * torch.sqrt(torch.tensor(2.0 / self.n_components))\n",
    "        \n",
    "        return self.classifier(features)\n",
    "    \n",
    "    def loss(self, Y_hat, Y, averaged=True):\n",
    "        \"\"\"Hinge loss + L2 regularization (controlled by C)\"\"\"\n",
    "        Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n",
    "        Y = Y.reshape((-1,))\n",
    "        \n",
    "        # Multi-class hinge loss\n",
    "        hinge_loss = F.multi_margin_loss(Y_hat, Y, reduction=\"mean\" if averaged else \"none\")\n",
    "        \n",
    "        # L2 regularization: alpha = 1 / C (higher C = less regularization)\n",
    "        alpha = 1.0 / self.C\n",
    "        l2_reg = alpha * 0.5 * torch.sum(self.classifier.weight ** 2)\n",
    "        \n",
    "        return hinge_loss + l2_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48499202",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df300fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    @staticmethod\n",
    "    def load_fashion_mnist(batch_size):\n",
    "        \"\"\"Load FashionMNIST dataset with train/validation/test split.\"\"\"\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        # Load full datasets\n",
    "        train_dataset = datasets.FashionMNIST(\n",
    "            root=\"./data\", train=True, transform=transform, download=True\n",
    "        )\n",
    "        test_dataset = datasets.FashionMNIST(\n",
    "            root=\"./data\", train=False, transform=transform, download=True\n",
    "        )\n",
    "        \n",
    "        # Split training data into train and validation sets\n",
    "        train_size = int(0.8 * len(train_dataset))  # 80% for training\n",
    "        val_size = len(train_dataset) - train_size  # 20% for validation\n",
    "        \n",
    "        train_subset, val_subset = torch.utils.data.random_split(\n",
    "            train_dataset, [train_size, val_size]\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        return train_loader, val_loader, test_loader\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(y_hat, y):\n",
    "        \"\"\"Compute number of correct predictions.\"\"\"\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        return (preds == y).float().sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_model(args, config=None):\n",
    "        \"\"\"Build model with optional config for hyperparameter optimization\"\"\"\n",
    "        if args.model_name == \"softmax\":\n",
    "            return SoftmaxRegression(num_outputs=args.num_outputs)\n",
    "        elif args.model_name == \"lenet\":\n",
    "            model = LeNet(num_classes=args.num_outputs)\n",
    "            model.apply_init()\n",
    "            return model\n",
    "        elif args.model_name == 'sgd':\n",
    "            # Use config values if provided, otherwise use args defaults\n",
    "            if config is None:\n",
    "                return SGDClassifier(num_classes=args.num_outputs, alpha=args.alpha, l1_ratio=args.l1_ratio)\n",
    "            else:\n",
    "                return SGDClassifier(\n",
    "                    num_classes=args.num_outputs,\n",
    "                    alpha=config.get('alpha', args.alpha),\n",
    "                    l1_ratio=config.get('l1_ratio', args.l1_ratio)\n",
    "                )\n",
    "        elif args.model_name == 'svm':\n",
    "            # Use config values if provided, otherwise use args defaults\n",
    "            if config is None:\n",
    "                return SVMClassifier(num_classes=args.num_outputs, C=args.C, gamma=args.gamma)\n",
    "            else:\n",
    "                return SVMClassifier(\n",
    "                    num_classes=args.num_outputs,\n",
    "                    C=config.get('C', args.C),\n",
    "                    gamma=config.get('gamma', args.gamma)\n",
    "                )\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                'Model type not supported, use \"softmax\", \"lenet\", \"sgd\", or \"svm\"'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae76034",
   "metadata": {},
   "source": [
    "## Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader, lr, num_epochs):\n",
    "        self.device = Config.device\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "        self.num_epochs = num_epochs\n",
    "    \n",
    "    def fit(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.train_epoch(epoch)\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        for X, y in tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{self.num_epochs}\"):\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "            y_hat = self.model(X)\n",
    "            loss = self.model.loss(y_hat, y)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "    def evaluate_train(self):\n",
    "        self.model.eval()\n",
    "        total_correct, total_samples = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X, y in self.train_loader:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                y_hat = self.model(X)\n",
    "                total_correct += Utils.accuracy(y_hat, y).item()\n",
    "                total_samples += y.size(0)\n",
    "        \n",
    "        return total_correct / total_samples\n",
    "    \n",
    "    def evaluate_test(self):\n",
    "        self.model.eval()\n",
    "        total_correct, total_samples = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X, y in self.test_loader:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                y_hat = self.model(X)\n",
    "                total_correct += Utils.accuracy(y_hat, y).item()\n",
    "                total_samples += y.size(0)\n",
    "        \n",
    "        return total_correct / total_samples\n",
    "    \n",
    "    def evaluate_val(self):\n",
    "        self.model.eval()\n",
    "        total_correct, total_samples = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X, y in self.val_loader:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                y_hat = self.model(X)\n",
    "                total_correct += Utils.accuracy(y_hat, y).item()\n",
    "                total_samples += y.size(0)\n",
    "        \n",
    "        return total_correct / total_samples\n",
    "    \n",
    "    def validation_error(self):\n",
    "        return 1.0 - self.evaluate_val()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448b69f1",
   "metadata": {},
   "source": [
    "## HPO Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2433240",
   "metadata": {},
   "source": [
    "##### Abstract base classes for modularity and extensibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256abb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPOSearcher(ABC):\n",
    "    \"\"\"Abstract base class for hyperparameter search strategies\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def sample_config(self) -> dict:\n",
    "        \"\"\"Sample new hyperparameter configuration\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def update(self, config: dict, error: float, additional_info=None):\n",
    "        \"\"\"Update searcher state after trial completion (optional)\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class HPOScheduler(ABC):\n",
    "    \"\"\"Abstract base class for scheduling trials\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def suggest(self) -> dict:\n",
    "        \"\"\"Suggest next configuration to evaluate\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def update(self, config: dict, error: float, info=None):\n",
    "        \"\"\"Update scheduler after trial completion\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d0590",
   "metadata": {},
   "source": [
    "##### Searcher classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSearcher(HPOSearcher):\n",
    "    \"\"\"Random search: samples configurations uniformly at random\"\"\"\n",
    "    \n",
    "    def __init__(self, config_space: dict, initial_config: dict):\n",
    "        self.config_space = config_space\n",
    "        self.initial_config = initial_config\n",
    "    \n",
    "    def sample_config(self) -> dict:\n",
    "        \"\"\"Sample random configuration from config space\"\"\"\n",
    "        # Use initial config first\n",
    "        if self.initial_config is not None:\n",
    "            config = self.initial_config\n",
    "            self.initial_config = None\n",
    "            return config\n",
    "        \n",
    "        # Sample from distributions\n",
    "        random_config = {key: domain.rvs() for key, domain in self.config_space.items()}\n",
    "        return random_config\n",
    "\n",
    "\n",
    "class BayesianSearcher(HPOSearcher):\n",
    "    \"\"\"\n",
    "    Bayesian Optimization using Gaussian Process + Expected Improvement.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Random initialization: Sample n_random_init configs randomly\n",
    "    2. Fit GP to observed (config, error) pairs\n",
    "    3. Optimize Expected Improvement acquisition function\n",
    "    4. Evaluate suggested config and repeat from step 2\n",
    "    \n",
    "    Key components:\n",
    "    - Surrogate model: Gaussian Process with Matérn 5/2 kernel\n",
    "    - Acquisition: Expected Improvement (balances exploration vs exploitation)\n",
    "    - Optimization: L-BFGS-B with 25 random restarts\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_space: dict, initial_config: dict, n_random_init=5):\n",
    "        self.config_space = config_space\n",
    "        self.initial_config = initial_config\n",
    "        self.n_random_init = n_random_init\n",
    "        self.trial_count = 0\n",
    "        \n",
    "        # Track observations\n",
    "        self.X_observed = []  # Configs as arrays\n",
    "        self.y_observed = []  # Validation errors\n",
    "        \n",
    "        # Build bounds for optimization\n",
    "        self.param_names = list(config_space.keys())\n",
    "        self.bounds = []\n",
    "        for key in self.param_names:\n",
    "            domain = config_space[key]\n",
    "            # domain.a = lower bound, domain.b = upper bound (from scipy.stats)\n",
    "            self.bounds.append((domain.a, domain.b))\n",
    "    \n",
    "    def sample_config(self) -> dict:\n",
    "        \"\"\"Sample next configuration using BO or random initialization\"\"\"\n",
    "        self.trial_count += 1\n",
    "        \n",
    "        # Use initial config first\n",
    "        if self.initial_config is not None:\n",
    "            config = self.initial_config\n",
    "            self.initial_config = None\n",
    "            return config\n",
    "        \n",
    "        # Random initialization phase\n",
    "        if self.trial_count <= self.n_random_init:\n",
    "            return {key: domain.rvs() for key, domain in self.config_space.items()}\n",
    "        \n",
    "        # Need at least 2 observations for GP\n",
    "        if len(self.X_observed) < 2:\n",
    "            return {key: domain.rvs() for key, domain in self.config_space.items()}\n",
    "        \n",
    "        # Bayesian optimization phase\n",
    "        try:\n",
    "            X = np.array(self.X_observed)\n",
    "            y = np.array(self.y_observed)\n",
    "            \n",
    "            # Fit Gaussian Process\n",
    "            kernel = Matern(nu=2.5)  # Matérn 5/2 kernel (smooth but not infinitely differentiable)\n",
    "            gp = GaussianProcessRegressor(\n",
    "                kernel=kernel,\n",
    "                alpha=1e-6,  # Noise level\n",
    "                normalize_y=True,  # Normalize targets\n",
    "                n_restarts_optimizer=5\n",
    "            )\n",
    "            gp.fit(X, y)\n",
    "            \n",
    "            # Optimize Expected Improvement acquisition function\n",
    "            next_x = self.optimize_acquisition(gp, y.min())\n",
    "            \n",
    "            # Convert array back to config dict\n",
    "            config = {name: float(next_x[i]) for i, name in enumerate(self.param_names)}\n",
    "            \n",
    "            # Handle integer parameters (like batch_size)\n",
    "            for key, domain in self.config_space.items():\n",
    "                if isinstance(domain, stats._distn_infrastructure.rv_discrete_frozen):\n",
    "                    config[key] = int(round(config[key]))\n",
    "            \n",
    "            return config\n",
    "        except Exception as e:\n",
    "            print(f\"  BO failed ({e}), falling back to random sampling\")\n",
    "            return {key: domain.rvs() for key, domain in self.config_space.items()}\n",
    "    \n",
    "    def update(self, config: dict, error: float, additional_info=None):\n",
    "        \"\"\"Record observation for GP fitting\"\"\"\n",
    "        # Convert config dict to array (in consistent order)\n",
    "        x = np.array([config[name] for name in self.param_names])\n",
    "        self.X_observed.append(x)\n",
    "        self.y_observed.append(error)\n",
    "    \n",
    "    def optimize_acquisition(self, gp, y_min, n_restarts=25):\n",
    "        \"\"\"\n",
    "        Optimize Expected Improvement acquisition function using L-BFGS-B.\n",
    "        Uses multi-start optimization to avoid local optima.\n",
    "        \"\"\"\n",
    "        best_x = None\n",
    "        best_acquisition_value = -np.inf\n",
    "        \n",
    "        # Multi-start optimization\n",
    "        for _ in range(n_restarts):\n",
    "            # Random starting point within bounds\n",
    "            x0 = np.array([np.random.uniform(low, high) for low, high in self.bounds])\n",
    "            \n",
    "            # Minimize negative EI (maximize EI)\n",
    "            result = minimize(\n",
    "                fun=lambda x: -self.expected_improvement(x, gp, y_min),\n",
    "                x0=x0,\n",
    "                bounds=self.bounds,\n",
    "                method='L-BFGS-B'\n",
    "            )\n",
    "            \n",
    "            if result.success and -result.fun > best_acquisition_value:\n",
    "                best_acquisition_value = -result.fun\n",
    "                best_x = result.x\n",
    "        \n",
    "        return best_x if best_x is not None else x0\n",
    "    \n",
    "    def expected_improvement(self, x, gp, y_min, xi=0.01):\n",
    "        \"\"\"\n",
    "        Expected Improvement acquisition function.\n",
    "        \n",
    "        EI(x) = E[max(y_min - f(x) - xi, 0)]\n",
    "             = (y_min - mu - xi) * Φ(Z) + sigma * φ(Z)\n",
    "        \n",
    "        where Z = (y_min - mu - xi) / sigma\n",
    "              Φ = CDF of standard normal\n",
    "              φ = PDF of standard normal\n",
    "        \n",
    "        Args:\n",
    "            x: Configuration to evaluate\n",
    "            gp: Fitted Gaussian Process\n",
    "            y_min: Current best (minimum) observation\n",
    "            xi: Exploration-exploitation trade-off (higher = more exploration)\n",
    "        \"\"\"\n",
    "        x = x.reshape(1, -1)\n",
    "        mu, sigma = gp.predict(x, return_std=True)\n",
    "        mu = mu[0]\n",
    "        sigma = sigma[0]\n",
    "        \n",
    "        if sigma == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # EI formula\n",
    "        z = (y_min - mu - xi) / sigma\n",
    "        ei = (y_min - mu - xi) * stats.norm.cdf(z) + sigma * stats.norm.pdf(z)\n",
    "        return ei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0869b0",
   "metadata": {},
   "source": [
    "##### Scheduler classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126796b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicScheduler(HPOScheduler):\n",
    "    \"\"\"Basic scheduler: directly delegates to searcher (no multi-fidelity)\"\"\"\n",
    "    \n",
    "    def __init__(self, searcher: HPOSearcher):\n",
    "        self.searcher = searcher\n",
    "    \n",
    "    def suggest(self) -> dict:\n",
    "        \"\"\"Suggest next configuration\"\"\"\n",
    "        return self.searcher.sample_config()\n",
    "    \n",
    "    def update(self, config: dict, error: float, info=None):\n",
    "        \"\"\"Update searcher with trial results\"\"\"\n",
    "        self.searcher.update(config, error, additional_info=info)\n",
    "\n",
    "\n",
    "class MultiFidelityScheduler(HPOScheduler):\n",
    "    \"\"\"\n",
    "    Successive Halving (SH) - Synchronous multi-fidelity scheduler.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Sample N configurations\n",
    "    2. Evaluate all on rung r_min\n",
    "    3. Keep top N/eta, discard rest\n",
    "    4. Promote survivors to next rung r_min * eta\n",
    "    5. Repeat until reaching r_max\n",
    "    \n",
    "    Key features:\n",
    "    - Synchronous: waits for all configs at a rung before promoting\n",
    "    - Aggressive early stopping of poor configs\n",
    "    - Rungs: [r_min, r_min*eta, r_min*eta^2, ..., r_max]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, searcher, eta, r_min, r_max, prefact):\n",
    "        self.searcher = searcher\n",
    "        self.eta = eta  # Reduction factor\n",
    "        self.r_min = r_min  # Minimum resource (epochs)\n",
    "        self.r_max = r_max  # Maximum resource (epochs)\n",
    "        self.prefact = prefact\n",
    "        \n",
    "        # Compute rung levels\n",
    "        self.K = int(np.log(r_max / r_min) / np.log(eta))\n",
    "        self.rung_levels = [r_min * (eta ** k) for k in range(self.K + 1)]\n",
    "        if r_max not in self.rung_levels:\n",
    "            self.rung_levels.append(r_max)\n",
    "        \n",
    "        # Bookkeeping\n",
    "        self.observed_error_at_rungs = defaultdict(list)  # For promotion decisions\n",
    "        self.all_observed_error_at_rungs = defaultdict(list)  # For tracking all results\n",
    "        self.queue = []  # Processing queue\n",
    "    \n",
    "    def suggest(self):\n",
    "        \"\"\"Suggest next configuration to evaluate\"\"\"\n",
    "        if len(self.queue) == 0:\n",
    "            # Sample new configurations for first rung\n",
    "            n_configs = int(self.prefact * (self.eta ** self.K))\n",
    "            configs = [self.searcher.sample_config() for _ in range(n_configs)]\n",
    "            for config in configs:\n",
    "                config[\"num_epochs\"] = self.r_min\n",
    "            self.queue.extend(configs)\n",
    "        \n",
    "        return self.queue.pop(0)\n",
    "    \n",
    "    def update(self, config: dict, error: float, info=None):\n",
    "        \"\"\"Update scheduler after trial completion\"\"\"\n",
    "        ri = int(config[\"num_epochs\"])  # Current rung\n",
    "        \n",
    "        # Update searcher\n",
    "        self.searcher.update(config, error, additional_info=info)\n",
    "        self.all_observed_error_at_rungs[ri].append((config, error))\n",
    "        \n",
    "        if ri < self.r_max:\n",
    "            # Store for promotion decision\n",
    "            self.observed_error_at_rungs[ri].append((config, error))\n",
    "            \n",
    "            # Check if we should promote configs to next rung\n",
    "            rung_idx = self.rung_levels.index(ri)\n",
    "            next_rung = self.rung_levels[rung_idx + 1]\n",
    "            n_required = int(self.prefact * (self.eta ** (self.K - rung_idx - 1)))\n",
    "            \n",
    "            if len(self.observed_error_at_rungs[ri]) >= n_required * self.eta:\n",
    "                # Promote top configs\n",
    "                top_configs = self.get_top_n_configurations(ri, n_required)\n",
    "                for config in top_configs:\n",
    "                    promoted_config = config.copy()\n",
    "                    promoted_config[\"num_epochs\"] = next_rung\n",
    "                    self.queue.append(promoted_config)\n",
    "                \n",
    "                # Clear rung for next round\n",
    "                self.observed_error_at_rungs[ri] = []\n",
    "    \n",
    "    def get_top_n_configurations(self, rung_level, n):\n",
    "        \"\"\"Get top n configurations from a rung based on error\"\"\"\n",
    "        rung = self.observed_error_at_rungs[rung_level]\n",
    "        if not rung:\n",
    "            return []\n",
    "        sorted_rung = sorted(rung, key=lambda x: x[1])\n",
    "        return [x[0] for x in sorted_rung[:n]]\n",
    "\n",
    "\n",
    "class ASHAScheduler(HPOScheduler):\n",
    "    \"\"\"\n",
    "    ASHA (Asynchronous Successive Halving Algorithm).\n",
    "    \n",
    "    Key differences from synchronous SH:\n",
    "    - Asynchronous: promotes configs as soon as enough results are available\n",
    "    - No synchronization barriers between rungs\n",
    "    - Better resource utilization (no worker idle time)\n",
    "    - Checks rungs from top to bottom for promotion opportunities\n",
    "    \n",
    "    Algorithm:\n",
    "    1. If no promotable configs, sample new config at r_min\n",
    "    2. Otherwise, promote best config from highest rung with enough completed trials\n",
    "    3. Track which configs have been promoted to avoid duplicates\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, searcher, eta, r_min, r_max, prefact=1):\n",
    "        self.searcher = searcher\n",
    "        self.eta = eta\n",
    "        self.r_min = r_min\n",
    "        self.r_max = r_max\n",
    "        self.prefact = prefact\n",
    "        \n",
    "        # Compute rung levels\n",
    "        self.K = int(np.log(r_max / r_min) / np.log(eta))\n",
    "        self.rung_levels = [r_min * (eta ** k) for k in range(self.K + 1)]\n",
    "        if r_max not in self.rung_levels:\n",
    "            self.rung_levels.append(r_max)\n",
    "        \n",
    "        # Track completed trials at each rung\n",
    "        self.completed_trials_at_rungs = defaultdict(list)  # [(config, error), ...]\n",
    "        \n",
    "        # Track promoted configs (to avoid duplicate promotions)\n",
    "        self.promoted_configs = defaultdict(set)  # {rung: {config_hash, ...}}\n",
    "    \n",
    "    def _config_hash(self, config):\n",
    "        \"\"\"Create hashable representation of config\"\"\"\n",
    "        # Exclude num_epochs from hash\n",
    "        items = [(k, v) for k, v in sorted(config.items()) if k != \"num_epochs\"]\n",
    "        return tuple(items)\n",
    "    \n",
    "    def suggest(self):\n",
    "        \"\"\"Suggest next configuration (either new or promoted)\"\"\"\n",
    "        # Check rungs from top to bottom for promotion opportunities\n",
    "        for i in range(len(self.rung_levels) - 2, -1, -1):\n",
    "            rung = self.rung_levels[i]\n",
    "            next_rung = self.rung_levels[i + 1]\n",
    "            \n",
    "            # Calculate how many configs should have been tried at this rung\n",
    "            k = self.K - i\n",
    "            n_required = int(self.prefact * (self.eta ** k))\n",
    "            \n",
    "            # Check if we have enough completed trials\n",
    "            n_completed = len(self.completed_trials_at_rungs[rung])\n",
    "            n_promoted = len(self.promoted_configs[rung])\n",
    "            \n",
    "            # Can we promote another config?\n",
    "            if n_completed >= n_required and n_promoted < n_required:\n",
    "                # Get best unpromoted config\n",
    "                trials_at_rung = sorted(self.completed_trials_at_rungs[rung], key=lambda x: x[1])\n",
    "                \n",
    "                for config, error in trials_at_rung:\n",
    "                    config_hash = self._config_hash(config)\n",
    "                    if config_hash not in self.promoted_configs[rung]:\n",
    "                        # Promote this config\n",
    "                        self.promoted_configs[rung].add(config_hash)\n",
    "                        promoted_config = config.copy()\n",
    "                        promoted_config[\"num_epochs\"] = next_rung\n",
    "                        return promoted_config\n",
    "        \n",
    "        # No promotions available, sample new config at r_min\n",
    "        config = self.searcher.sample_config()\n",
    "        config[\"num_epochs\"] = self.r_min\n",
    "        return config\n",
    "    \n",
    "    def update(self, config: dict, error: float, info=None):\n",
    "        \"\"\"Update scheduler after trial completion\"\"\"\n",
    "        ri = int(config[\"num_epochs\"])\n",
    "        \n",
    "        # Update searcher\n",
    "        self.searcher.update(config, error, additional_info=info)\n",
    "        \n",
    "        # Record completed trial\n",
    "        self.completed_trials_at_rungs[ri].append((config, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89908a81",
   "metadata": {},
   "source": [
    "##### Tuner class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95132a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPOTuner:\n",
    "    \"\"\"Main tuner that orchestrates the HPO process\"\"\"\n",
    "    \n",
    "    def __init__(self, scheduler: HPOScheduler, objective_fn: callable):\n",
    "        self.scheduler = scheduler\n",
    "        self.objective_fn = objective_fn\n",
    "        self.incumbent = None  # Best config found\n",
    "        self.incumbent_error = None  # Best error achieved\n",
    "        self.incumbent_trajectory = []  # Track best error over time\n",
    "        self.cumulative_runtime = []  # Track cumulative runtime\n",
    "        self.current_runtime = 0\n",
    "        self.records = []  # All trial records\n",
    "    \n",
    "    def run(self, number_of_trials):\n",
    "        \"\"\"Run HPO for specified number of trials\"\"\"\n",
    "        for i in range(number_of_trials):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Get next configuration to evaluate\n",
    "            config = self.scheduler.suggest()\n",
    "            print(f\"Trial {i+1}/{number_of_trials} config: {config}\")\n",
    "            \n",
    "            # Evaluate configuration\n",
    "            error = self.objective_fn(config)\n",
    "            \n",
    "            # Update scheduler with results\n",
    "            self.scheduler.update(config, error)\n",
    "            \n",
    "            # Track performance and runtime\n",
    "            runtime = time.time() - start_time\n",
    "            self.bookkeeping(config, error, runtime)\n",
    "            print(f\"  Validation error: {error:.4f} - Runtime: {runtime:.2f}s\")\n",
    "    \n",
    "    def bookkeeping(self, config: dict, error: float, runtime: float):\n",
    "        \"\"\"Track best configuration and performance\"\"\"\n",
    "        self.records.append({\"config\": config, \"error\": error, \"runtime\": runtime})\n",
    "        \n",
    "        # Update incumbent (best config so far)\n",
    "        if self.incumbent is None or error < self.incumbent_error:\n",
    "            self.incumbent = config\n",
    "            self.incumbent_error = error\n",
    "        \n",
    "        # Track trajectories for visualization\n",
    "        self.incumbent_trajectory.append(self.incumbent_error)\n",
    "        self.current_runtime += runtime\n",
    "        self.cumulative_runtime.append(self.current_runtime)\n",
    "    \n",
    "    def get_best_config(self):\n",
    "        \"\"\"Return best configuration and its error\"\"\"\n",
    "        return self.incumbent, self.incumbent_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1dd2f9",
   "metadata": {},
   "source": [
    "## Completed HPO Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPO:\n",
    "    @staticmethod\n",
    "    def hpo_objective_fn(args):\n",
    "        \"\"\"\n",
    "        Create objective function for HPO.\n",
    "        Returns a function that evaluates a configuration and returns validation error.\n",
    "        \"\"\"\n",
    "        def hpo_objective(config):\n",
    "            lr = config.get(\"learning_rate\", args.learning_rate)\n",
    "            batch_size = config.get(\"batch_size\", args.batch_size)\n",
    "            num_epochs = config.get(\"num_epochs\", args.num_epochs)\n",
    "            \n",
    "            # Load data\n",
    "            train_loader, val_loader, test_loader = Utils.load_fashion_mnist(batch_size)\n",
    "            \n",
    "            # Build model (handles model-specific hyperparameters via config)\n",
    "            model = Utils.build_model(args, config)\n",
    "            \n",
    "            # Train model\n",
    "            trainer = Trainer(\n",
    "                model,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                test_loader,\n",
    "                lr=lr,\n",
    "                num_epochs=num_epochs,\n",
    "            )\n",
    "            trainer.fit()\n",
    "            \n",
    "            # Return validation error\n",
    "            val_err = trainer.validation_error()\n",
    "            return val_err\n",
    "        \n",
    "        return hpo_objective\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_search(args, config_space, initial_config):\n",
    "        \"\"\"Run Random Search HPO\"\"\"\n",
    "        searcher = RandomSearcher(config_space, initial_config)\n",
    "        scheduler = BasicScheduler(searcher)\n",
    "        objective_fn = HPO.hpo_objective_fn(args)\n",
    "        tuner = HPOTuner(scheduler=scheduler, objective_fn=objective_fn)\n",
    "        \n",
    "        print(f\"Starting Random Search with {args.num_trials} trials\")\n",
    "        tuner.run(number_of_trials=args.num_trials)\n",
    "        \n",
    "        best_config, best_score = tuner.get_best_config()\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"Random Search HPO Summary:\")\n",
    "        print(f\"Best config: {best_config}\")\n",
    "        print(f\"Best validation error: {best_score:.4f}\")\n",
    "        print(f\"Total runtime: {tuner.current_runtime:.2f}s\")\n",
    "        print(f\"Average time per trial: {tuner.current_runtime/args.num_trials:.2f}s\")\n",
    "        \n",
    "        return best_config, best_score, tuner\n",
    "    \n",
    "    @staticmethod\n",
    "    def bayesian_search(args, config_space, initial_config, n_random_init=5):\n",
    "        \"\"\"\n",
    "        Run Bayesian Optimization using Gaussian Process + Expected Improvement.\n",
    "        \n",
    "        Args:\n",
    "            n_random_init: Number of random trials before starting BO\n",
    "        \"\"\"\n",
    "        searcher = BayesianSearcher(config_space, initial_config, n_random_init=n_random_init)\n",
    "        scheduler = BasicScheduler(searcher)\n",
    "        objective_fn = HPO.hpo_objective_fn(args)\n",
    "        tuner = HPOTuner(scheduler=scheduler, objective_fn=objective_fn)\n",
    "        \n",
    "        print(f\"Starting Bayesian HPO with {args.num_trials} trials\")\n",
    "        print(f\"  Random initialization: {n_random_init} trials\")\n",
    "        print(f\"  Bayesian optimization: {args.num_trials - n_random_init} trials\")\n",
    "        tuner.run(number_of_trials=args.num_trials)\n",
    "        \n",
    "        best_config, best_score = tuner.get_best_config()\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"Bayesian HPO Summary:\")\n",
    "        print(f\"Best config: {best_config}\")\n",
    "        print(f\"Best validation error: {best_score:.4f}\")\n",
    "        print(f\"Total runtime: {tuner.current_runtime:.2f}s\")\n",
    "        print(f\"Average time per trial: {tuner.current_runtime/args.num_trials:.2f}s\")\n",
    "        \n",
    "        return best_config, best_score, tuner\n",
    "    \n",
    "    @staticmethod\n",
    "    def multi_fidelity_random_search(args, config_space, initial_config):\n",
    "        \"\"\"Run Successive Halving (synchronous multi-fidelity)\"\"\"\n",
    "        searcher = RandomSearcher(config_space, initial_config)\n",
    "        scheduler = MultiFidelityScheduler(\n",
    "            searcher=searcher,\n",
    "            eta=args.eta,\n",
    "            r_min=args.min_number_of_epochs,\n",
    "            r_max=args.max_number_of_epochs,\n",
    "            prefact=args.prefact,\n",
    "        )\n",
    "        objective_fn = HPO.hpo_objective_fn(args)\n",
    "        tuner = HPOTuner(scheduler=scheduler, objective_fn=objective_fn)\n",
    "        \n",
    "        print(f\"Starting Successive Halving with {args.num_trials} trials\")\n",
    "        print(f\"Rung levels: {scheduler.rung_levels}\")\n",
    "        print(f\"eta={args.eta}, r_min={args.min_number_of_epochs}, r_max={args.max_number_of_epochs}\")\n",
    "        tuner.run(number_of_trials=args.num_trials)\n",
    "        \n",
    "        best_config, best_score = tuner.get_best_config()\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"Successive Halving HPO Summary:\")\n",
    "        print(f\"Best config: {best_config}\")\n",
    "        print(f\"Best validation error: {best_score:.4f}\")\n",
    "        print(f\"Total runtime: {tuner.current_runtime:.2f}s\")\n",
    "        print(f\"Average time per trial: {tuner.current_runtime/args.num_trials:.2f}s\")\n",
    "        \n",
    "        return best_config, best_score, tuner\n",
    "    \n",
    "    @staticmethod\n",
    "    def asha_random_search(args, config_space, initial_config):\n",
    "        \"\"\"Run ASHA (Asynchronous Successive Halving)\"\"\"\n",
    "        searcher = RandomSearcher(config_space, initial_config)\n",
    "        scheduler = ASHAScheduler(\n",
    "            searcher=searcher,\n",
    "            eta=args.eta,\n",
    "            r_min=args.min_number_of_epochs,\n",
    "            r_max=args.max_number_of_epochs,\n",
    "            prefact=args.prefact,\n",
    "        )\n",
    "        objective_fn = HPO.hpo_objective_fn(args)\n",
    "        tuner = HPOTuner(scheduler=scheduler, objective_fn=objective_fn)\n",
    "        \n",
    "        print(f\"Starting ASHA with {args.num_trials} trials\")\n",
    "        print(f\"Rung levels: {scheduler.rung_levels}\")\n",
    "        print(f\"eta={args.eta}, r_min={args.min_number_of_epochs}, r_max={args.max_number_of_epochs}\")\n",
    "        \n",
    "        tuner.run(number_of_trials=args.num_trials)\n",
    "        best_config, best_score = tuner.get_best_config()\n",
    "        \n",
    "        # Print rung statistics\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ASHA Rung Statistics:\")\n",
    "        for rung in scheduler.rung_levels:\n",
    "            n_completed = len(scheduler.completed_trials_at_rungs[rung])\n",
    "            n_promoted = len(scheduler.promoted_configs[rung])\n",
    "            print(f\"  Rung {rung:3d}: {n_completed:3d} completed, {n_promoted:3d} promoted\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"ASHA HPO Summary:\")\n",
    "        print(f\"Best config: {best_config}\")\n",
    "        print(f\"Best validation error: {best_score:.4f}\")\n",
    "        print(f\"Total runtime: {tuner.current_runtime:.2f}s\")\n",
    "        print(f\"Average time per trial: {tuner.current_runtime/args.num_trials:.2f}s\")\n",
    "        \n",
    "        return best_config, best_score, tuner\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_hpo_progress(tuner, save_path=None):\n",
    "        \"\"\"Plot HPO progress over time\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Plot incumbent error vs trials\n",
    "        ax1.plot(range(len(tuner.incumbent_trajectory)), tuner.incumbent_trajectory, 'b-', linewidth=2, marker='o', markersize=4)\n",
    "        ax1.set_xlabel(\"Trial Number\", fontsize=12)\n",
    "        ax1.set_ylabel(\"Best Validation Error\", fontsize=12)\n",
    "        ax1.set_title(\"HPO Progress: Best Error vs Trials\", fontsize=14, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_ylim([min(tuner.incumbent_trajectory) * 0.95, max(tuner.incumbent_trajectory) * 1.05])\n",
    "        \n",
    "        # Plot incumbent error vs cumulative runtime\n",
    "        ax2.plot(tuner.cumulative_runtime, tuner.incumbent_trajectory, 'r-', linewidth=2, marker='s', markersize=4)\n",
    "        ax2.set_xlabel(\"Cumulative Runtime (s)\", fontsize=12)\n",
    "        ax2.set_ylabel(\"Best Validation Error\", fontsize=12)\n",
    "        ax2.set_title(\"HPO Progress: Best Error vs Time\", fontsize=14, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_ylim([min(tuner.incumbent_trajectory) * 0.95, max(tuner.incumbent_trajectory) * 1.05])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "            print(f\"Plot saved to {save_path}\")\n",
    "        plt.show()\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab9e34c",
   "metadata": {},
   "source": [
    "## Examples: Running HPO Experiments\n",
    "\n",
    "The following examples demonstrate all 4 HPO algorithms on different models.\n",
    "\n",
    "**Key Points:**\n",
    "- Each example runs HPO to find best hyperparameters\n",
    "- After HPO, we train a final model with the best config\n",
    "- For multi-fidelity (SH, ASHA), use `max_number_of_epochs` for final training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1582b760",
   "metadata": {},
   "source": [
    "## Random Search with Simple Hyperparameters like Learning Rate or Batch Size\n",
    "\n",
    "The following examples show how to optimize simple hyperparameters (learning rate, batch size) using Random Search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94a8942",
   "metadata": {},
   "source": [
    "## Example 1: Random Search - Basic (Softmax Regression)\n",
    "\n",
    "Random Search is the simplest HPO algorithm - it samples configurations uniformly at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure arguments\n",
    "args = Args()\n",
    "args.model_name = \"softmax\"\n",
    "args.num_trials = 10\n",
    "args.eta = 2\n",
    "args.min_number_of_epochs = 5\n",
    "args.max_number_of_epochs = 20\n",
    "args.prefact = 1\n",
    "\n",
    "# Define search space\n",
    "config_space = {\n",
    "    \"learning_rate\": stats.loguniform(1e-4, 1),\n",
    "    \"batch_size\": stats.randint(32, 512),\n",
    "}\n",
    "\n",
    "initial_config = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"batch_size\": 256,\n",
    "}\n",
    "\n",
    "# Run basic random search\n",
    "best_config, best_score, tuner = HPO.random_search(\n",
    "    args, config_space=config_space, initial_config=initial_config\n",
    ")\n",
    "\n",
    "# Plot progress\n",
    "HPO.plot_hpo_progress(tuner)\n",
    "\n",
    "# Train final model with best config\n",
    "print(f\"\\nTraining final model with best config: {best_config}\")\n",
    "train_loader, val_loader, test_loader = Utils.load_fashion_mnist(\n",
    "    best_config[\"batch_size\"]\n",
    ")\n",
    "model = Utils.build_model(args, best_config)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=best_config[\"learning_rate\"],\n",
    "    num_epochs=args.num_epochs,\n",
    ")\n",
    "trainer.fit()\n",
    "\n",
    "train_acc = trainer.evaluate_train()\n",
    "val_acc = 1.0 - trainer.validation_error()\n",
    "test_acc = trainer.evaluate_test()\n",
    "\n",
    "print(f\"Final train accuracy with Random-tuned hyperparameters: {train_acc:.4f}\")\n",
    "print(f\"Final validation accuracy with Random-tuned hyperparameters: {val_acc:.4f}\")\n",
    "print(f\"Final test accuracy with Random-tuned hyperparameters: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479396f1",
   "metadata": {},
   "source": [
    "## Example 2: Random Search - Successive Halving (LeNet)\n",
    "\n",
    "Successive Halving (SH) is a multi-fidelity algorithm that aggressively prunes poorly-performing configurations early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79010dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure arguments for multi-fidelity\n",
    "args = Args()\n",
    "args.model_name = \"lenet\"\n",
    "args.num_trials = 10\n",
    "args.eta = 2\n",
    "args.min_number_of_epochs = 5\n",
    "args.max_number_of_epochs = 20\n",
    "args.prefact = 1\n",
    "\n",
    "# Define search space (same as before)\n",
    "config_space = {\n",
    "    \"learning_rate\": stats.loguniform(1e-4, 1),\n",
    "    \"batch_size\": stats.randint(32, 512),\n",
    "}\n",
    "\n",
    "initial_config = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"batch_size\": 256,\n",
    "}\n",
    "\n",
    "# Run multi-fidelity HPO (Successive Halving)\n",
    "best_config, best_score, tuner = HPO.multi_fidelity_random_search(\n",
    "    args, config_space=config_space, initial_config=initial_config\n",
    ")\n",
    "\n",
    "# Plot progress\n",
    "HPO.plot_hpo_progress(tuner)\n",
    "\n",
    "# Train final model with best config\n",
    "print(f\"\\nTraining final model with best config: {best_config}\")\n",
    "train_loader, val_loader, test_loader = Utils.load_fashion_mnist(\n",
    "    best_config[\"batch_size\"]\n",
    ")\n",
    "model = Utils.build_model(args, best_config)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=best_config[\"learning_rate\"],\n",
    "    num_epochs=args.max_number_of_epochs,  # Use max epochs for final training\n",
    ")\n",
    "trainer.fit()\n",
    "\n",
    "train_acc = trainer.evaluate_train()\n",
    "val_acc = 1.0 - trainer.validation_error()\n",
    "test_acc = trainer.evaluate_test()\n",
    "\n",
    "print(f\"Final train accuracy with Successive Halving-tuned hyperparameters: {train_acc:.4f}\")\n",
    "print(f\"Final validation accuracy with Successive Halving-tuned hyperparameters: {val_acc:.4f}\")\n",
    "print(f\"Final test accuracy with Successive Halving-tuned hyperparameters: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e1c59",
   "metadata": {},
   "source": [
    "## Example 3: Random Search - ASHA (LeNet)\n",
    "\n",
    "ASHA is an asynchronous version of Successive Halving that promotes configs without waiting for synchronization barriers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure arguments for ASHA\n",
    "args = Args()\n",
    "args.model_name = \"lenet\"\n",
    "args.num_trials = 20\n",
    "args.eta = 2\n",
    "args.min_number_of_epochs = 5\n",
    "args.max_number_of_epochs = 20\n",
    "args.prefact = 1\n",
    "\n",
    "# Define search space\n",
    "config_space = {\n",
    "    \"learning_rate\": stats.loguniform(1e-4, 1),\n",
    "    \"batch_size\": stats.randint(32, 512),\n",
    "}\n",
    "\n",
    "initial_config = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"batch_size\": 256,\n",
    "}\n",
    "\n",
    "# Run ASHA\n",
    "best_config, best_score, tuner = HPO.asha_random_search(\n",
    "    args, config_space=config_space, initial_config=initial_config\n",
    ")\n",
    "\n",
    "# Plot progress\n",
    "HPO.plot_hpo_progress(tuner)\n",
    "\n",
    "# Train final model with best config\n",
    "print(f\"\\nTraining final model with best config: {best_config}\")\n",
    "train_loader, val_loader, test_loader = Utils.load_fashion_mnist(\n",
    "    best_config[\"batch_size\"]\n",
    ")\n",
    "model = Utils.build_model(args, best_config)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=best_config[\"learning_rate\"],\n",
    "    num_epochs=args.max_number_of_epochs,  # Use max epochs for final training\n",
    ")\n",
    "trainer.fit()\n",
    "\n",
    "train_acc = trainer.evaluate_train()\n",
    "val_acc = 1.0 - trainer.validation_error()\n",
    "test_acc = trainer.evaluate_test()\n",
    "\n",
    "print(f\"Final train accuracy with ASHA-tuned hyperparameters: {train_acc:.4f}\")\n",
    "print(f\"Final validation accuracy with ASHA-tuned hyperparameters: {val_acc:.4f}\")\n",
    "print(f\"Final test accuracy with ASHA-tuned hyperparameters: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0699f32",
   "metadata": {},
   "source": [
    "## Bayesian Optimization with Model-Specific Hyperparameters\n",
    "\n",
    "The following examples show how to optimize model-specific hyperparameters (alpha, l1_ratio, C, gamma) using Bayesian Optimization.\n",
    "\n",
    "Bayesian Optimization uses a Gaussian Process to model the objective function and Expected Improvement to select promising configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0584529",
   "metadata": {},
   "source": [
    "## Example 4: Bayesian Optimization (SVMClassifier)\n",
    "\n",
    "Optimize SVM's penalty parameter `C` and RBF kernel coefficient `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226106af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure for SVMClassifier\n",
    "args = Args()\n",
    "args.model_name = \"svm\"\n",
    "args.num_trials = 15\n",
    "args.num_epochs = 10\n",
    "\n",
    "# Define search space for SVM (optimize C and gamma)\n",
    "config_space = {\n",
    "    \"learning_rate\": stats.loguniform(1e-4, 1),\n",
    "    \"batch_size\": stats.randint(32, 512),\n",
    "    \"C\": stats.loguniform(1e-2, 1e2),           # Penalty parameter\n",
    "    \"gamma\": stats.loguniform(1e-6, 1e-1),      # RBF kernel coefficient\n",
    "}\n",
    "\n",
    "initial_config = {\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"batch_size\": 256,\n",
    "    \"C\": 1.0,\n",
    "    \"gamma\": 0.001,\n",
    "}\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "best_config, best_score, tuner = HPO.bayesian_search(\n",
    "    args, \n",
    "    config_space=config_space, \n",
    "    initial_config=initial_config,\n",
    "    n_random_init=5\n",
    ")\n",
    "\n",
    "# Plot progress\n",
    "HPO.plot_hpo_progress(tuner)\n",
    "\n",
    "print(f\"\\n{'='*32}\")\n",
    "print(\"Best SVMClassifier Configuration:\")\n",
    "print(f\"  Learning rate: {best_config['learning_rate']:.6f}\")\n",
    "print(f\"  Batch size: {best_config['batch_size']}\")\n",
    "print(f\"  C (penalty): {best_config['C']:.4f}\")\n",
    "print(f\"  Gamma (kernel coef): {best_config['gamma']:.6f}\")\n",
    "\n",
    "# Train final model with best config\n",
    "print(f\"\\nTraining final model with best config: {best_config}\")\n",
    "train_loader, val_loader, test_loader = Utils.load_fashion_mnist(\n",
    "    best_config[\"batch_size\"]\n",
    ")\n",
    "model = Utils.build_model(args, best_config)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=best_config[\"learning_rate\"],\n",
    "    num_epochs=args.num_epochs,\n",
    ")\n",
    "trainer.fit()\n",
    "\n",
    "train_acc = trainer.evaluate_train()\n",
    "val_acc = 1.0 - trainer.validation_error()\n",
    "test_acc = trainer.evaluate_test()\n",
    "\n",
    "print(f\"Final train accuracy with Bayesian-tuned hyperparameters: {train_acc:.4f}\")\n",
    "print(f\"Final validation accuracy with Bayesian-tuned hyperparameters: {val_acc:.4f}\")\n",
    "print(f\"Final test accuracy with Bayesian-tuned hyperparameters: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed4f865",
   "metadata": {},
   "source": [
    "## Example 4: Bayesian Optimization (SGDClassifier)\n",
    "\n",
    "Optimize SGD's regularization strength `alpha` and Elastic Net mixing parameter `l1_ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure for SGDClassifier\n",
    "args = Args()\n",
    "args.model_name = \"sgd\"\n",
    "args.num_trials = 15\n",
    "args.num_epochs = 10\n",
    "\n",
    "# Define search space for SGD (optimize alpha and l1_ratio)\n",
    "config_space = {\n",
    "    \"learning_rate\": stats.loguniform(1e-4, 1),\n",
    "    \"batch_size\": stats.randint(32, 512),\n",
    "    \"alpha\": stats.loguniform(1e-6, 1e-1),      # Regularization strength\n",
    "    \"l1_ratio\": stats.uniform(0, 1),            # Elastic net mixing (0=L2, 1=L1)\n",
    "}\n",
    "\n",
    "initial_config = {\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"batch_size\": 256,\n",
    "    \"alpha\": 0.0001,\n",
    "    \"l1_ratio\": 0.15,\n",
    "}\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "best_config, best_score, tuner = HPO.bayesian_search(\n",
    "    args, \n",
    "    config_space=config_space, \n",
    "    initial_config=initial_config,\n",
    "    n_random_init=5\n",
    ")\n",
    "\n",
    "# Plot progress\n",
    "HPO.plot_hpo_progress(tuner)\n",
    "\n",
    "print(f\"\\n{'='*32}\")\n",
    "print(\"Best SGDClassifier Configuration:\")\n",
    "print(f\"  Learning rate: {best_config['learning_rate']:.6f}\")\n",
    "print(f\"  Batch size: {best_config['batch_size']}\")\n",
    "print(f\"  Alpha (regularization): {best_config['alpha']:.6f}\")\n",
    "print(f\"  L1 ratio: {best_config['l1_ratio']:.4f}\")\n",
    "\n",
    "# Train final model with best config\n",
    "print(f\"\\nTraining final model with best config: {best_config}\")\n",
    "train_loader, val_loader, test_loader = Utils.load_fashion_mnist(\n",
    "    best_config[\"batch_size\"]\n",
    ")\n",
    "model = Utils.build_model(args, best_config)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=best_config[\"learning_rate\"],\n",
    "    num_epochs=args.num_epochs,\n",
    ")\n",
    "trainer.fit()\n",
    "\n",
    "train_acc = trainer.evaluate_train()\n",
    "val_acc = 1.0 - trainer.validation_error()\n",
    "test_acc = trainer.evaluate_test()\n",
    "\n",
    "print(f\"Final train accuracy with Bayesian-tuned hyperparameters: {train_acc:.4f}\")\n",
    "print(f\"Final validation accuracy with Bayesian-tuned hyperparameters: {val_acc:.4f}\")\n",
    "print(f\"Final test accuracy with Bayesian-tuned hyperparameters: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace07c9d",
   "metadata": {},
   "source": [
    "## Example 5: Bayesian Optimization (LeNet)\n",
    "\n",
    "Apply Bayesian Optimization to LeNet (only optimizing learning_rate and batch_size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbaf46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure arguments for Bayesian Optimization\n",
    "args = Args()\n",
    "args.model_name = \"lenet\"\n",
    "args.num_trials = 15  # 5 random init + 10 BO iterations\n",
    "args.num_epochs = 10\n",
    "\n",
    "# Define search space\n",
    "config_space = {\n",
    "    \"learning_rate\": stats.loguniform(1e-4, 1),\n",
    "    \"batch_size\": stats.randint(32, 512),\n",
    "}\n",
    "\n",
    "initial_config = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"batch_size\": 256,\n",
    "}\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "best_config, best_score, tuner = HPO.bayesian_search(\n",
    "    args, \n",
    "    config_space=config_space, \n",
    "    initial_config=initial_config,\n",
    "    n_random_init=5\n",
    ")\n",
    "\n",
    "# Plot progress\n",
    "HPO.plot_hpo_progress(tuner)\n",
    "\n",
    "# Train final model with best config\n",
    "print(f\"\\nTraining final model with best config: {best_config}\")\n",
    "train_loader, val_loader, test_loader = Utils.load_fashion_mnist(\n",
    "    best_config[\"batch_size\"]\n",
    ")\n",
    "model = Utils.build_model(args, best_config)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=best_config[\"learning_rate\"],\n",
    "    num_epochs=args.num_epochs,\n",
    ")\n",
    "trainer.fit()\n",
    "\n",
    "train_acc = trainer.evaluate_train()\n",
    "val_acc = 1.0 - trainer.validation_error()\n",
    "test_acc = trainer.evaluate_test()\n",
    "\n",
    "print(f\"Final train accuracy with Bayesian-tuned hyperparameters: {train_acc:.4f}\")\n",
    "print(f\"Final validation accuracy with Bayesian-tuned hyperparameters: {val_acc:.4f}\")\n",
    "print(f\"Final test accuracy with Bayesian-tuned hyperparameters: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba96be60",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### HPO Algorithms Comparison:\n",
    "\n",
    "| Algorithm | Search Strategy | Multi-Fidelity | Model-Based | Synchronous | Best Use Case |\n",
    "|-----------|----------------|----------------|-------------|-------------|---------------|\n",
    "| **Random Search** | Random sampling | No | No | Yes | Baseline, small search spaces |\n",
    "| **Bayesian Optimization** | GP + EI | No | Yes | Yes | Expensive evaluations, continuous spaces |\n",
    "| **Successive Halving** | Random + early stopping | Yes | No | Yes | Limited parallel workers |\n",
    "| **ASHA** | Random + early stopping | Yes | No | No | Many parallel workers, large-scale |\n",
    "\n",
    "### Models Supported:\n",
    "\n",
    "| Model | Type | Key Hyperparameters | Typical Accuracy | Speed |\n",
    "|-------|------|---------------------|------------------|-------|\n",
    "| **SoftmaxRegression** | Linear | lr, batch_size | ~82-85% | Fast |\n",
    "| **LeNet** | CNN | lr, batch_size | ~85-90% | Slow |\n",
    "| **SGDClassifier** | Linear SVM | lr, batch_size, alpha, l1_ratio | ~80-83% | Fast |\n",
    "| **SVMClassifier** | Kernel SVM | lr, batch_size, C, gamma | ~83-87% | Moderate |\n",
    "\n",
    "### Key Concepts Explained:\n",
    "\n",
    "#### Multi-Fidelity Optimization:\n",
    "- **Resource**: In our implementation, resource = `num_epochs` (training duration)\n",
    "- **Rung**: A checkpoint where configs are evaluated with a specific resource level\n",
    "- **eta (η)**: Reduction factor determining what fraction of configs advance (keep 1/η configs at each rung)\n",
    "- **r_min**: Minimum resource (minimum number of epochs, e.g., 5)\n",
    "- **r_max**: Maximum resource (maximum number of epochs, e.g., 20)\n",
    "- **Rung Levels**: `[r_min, r_min*η, r_min*η², ..., r_max]`\n",
    "\n",
    "Example with η=2, r_min=5, r_max=20:\n",
    "- Rungs: [5, 10, 20] epochs\n",
    "- If you start with 16 configs at rung 5, keep top 8 for rung 10, keep top 4 for rung 20\n",
    "\n",
    "#### Bayesian Optimization Components:\n",
    "- **Surrogate Model**: Gaussian Process with Matérn 5/2 kernel\n",
    "  - Models the unknown objective function: f(x) ~ GP(μ, k)\n",
    "  - Provides uncertainty estimates (mean and variance)\n",
    "- **Acquisition Function**: Expected Improvement (EI)\n",
    "  - EI(x) = E[max(f_min - f(x), 0)]\n",
    "  - Balances exploitation (promising areas) vs exploration (uncertain areas)\n",
    "  - Higher EI = more promising to evaluate\n",
    "- **Optimization**: L-BFGS-B with 25 random restarts\n",
    "  - Finds the x that maximizes EI(x)\n",
    "  - Multiple restarts to avoid local optima\n",
    "- **Random Initialization**: First n_random_init trials (default 5)\n",
    "  - Seeds the GP with diverse observations\n",
    "  - Ensures good coverage before starting BO\n",
    "\n",
    "#### Config Space Distributions (scipy.stats):\n",
    "- **`stats.loguniform(a, b)`**: Log-uniform distribution for learning rates, regularization parameters\n",
    "  - Samples uniformly in log-space: log(x) ~ Uniform(log(a), log(b))\n",
    "  - Good for parameters spanning multiple orders of magnitude\n",
    "  - Attributes: `domain.a` (lower bound), `domain.b` (upper bound)\n",
    "- **`stats.randint(low, high)`**: Discrete uniform for batch sizes\n",
    "  - Samples integers uniformly: x ~ Uniform({low, low+1, ..., high-1})\n",
    "- **`stats.uniform(a, b)`**: Uniform distribution for l1_ratio\n",
    "  - Samples uniformly: x ~ Uniform(a, b)\n",
    "\n",
    "**Important**: Use `scipy.stats` distributions (not `syne_tune`) for Bayesian Optimization because:\n",
    "- BayesianSearcher accesses `domain.a` and `domain.b` attributes\n",
    "- These attributes are specific to scipy.stats frozen distributions\n",
    "- Enables proper bounds for L-BFGS-B optimization\n",
    "\n",
    "### ASHA vs Successive Halving:\n",
    "\n",
    "**Successive Halving (Synchronous):**\n",
    "- Waits for all configs to complete at a rung before promoting\n",
    "- Synchronization barriers can cause worker idle time\n",
    "- All promotions happen together in batches\n",
    "\n",
    "**ASHA (Asynchronous):**\n",
    "- Promotes configs as soon as enough results are available\n",
    "- No synchronization barriers\n",
    "- Workers never idle waiting for others\n",
    "- Better resource utilization in distributed settings\n",
    "- Checks rungs from top to bottom for promotion opportunities\n",
    "\n",
    "### Implementation Details:\n",
    "\n",
    "#### 1. Model Building with Config:\n",
    "```python\n",
    "# Utils.build_model(args, config) handles model-specific hyperparameters\n",
    "model = Utils.build_model(args, config)\n",
    "\n",
    "# For SGD: extracts alpha and l1_ratio from config\n",
    "# For SVM: extracts C and gamma from config\n",
    "# Uses args.alpha, args.C, etc. as defaults if not in config\n",
    "```\n",
    "\n",
    "#### 2. HPO Objective Function:\n",
    "```python\n",
    "def hpo_objective(config):\n",
    "    # Extract hyperparameters\n",
    "    lr = config.get(\"learning_rate\", args.learning_rate)\n",
    "    batch_size = config.get(\"batch_size\", args.batch_size)\n",
    "    num_epochs = config.get(\"num_epochs\", args.num_epochs)\n",
    "    \n",
    "    # Build model (automatically handles model-specific params)\n",
    "    model = Utils.build_model(args, config)\n",
    "    \n",
    "    # Train and evaluate\n",
    "    trainer = Trainer(model, ..., lr=lr, num_epochs=num_epochs)\n",
    "    trainer.fit()\n",
    "    return trainer.validation_error()\n",
    "```\n",
    "\n",
    "#### 3. Final Training:\n",
    "After HPO finds the best config, train final model:\n",
    "```python\n",
    "train_loader, val_loader, test_loader = Utils.load_fashion_mnist(best_config[\"batch_size\"])\n",
    "model = Utils.build_model(args, best_config)  # Automatically sets alpha, C, gamma, etc.\n",
    "trainer = Trainer(model, ..., lr=best_config[\"learning_rate\"], num_epochs=args.num_epochs)\n",
    "trainer.fit()\n",
    "```\n",
    "\n",
    "### Recommended Settings:\n",
    "\n",
    "**Random Search:**\n",
    "- `num_trials`: 10-20 trials\n",
    "- Good baseline for comparison\n",
    "- Works well when you have prior knowledge of good regions\n",
    "\n",
    "**Bayesian Optimization:**\n",
    "- `num_trials`: 15-30 (5 random init + 10-25 BO iterations)\n",
    "- `n_random_init`: 5 (rule of thumb: 1-2 per hyperparameter)\n",
    "- Best for: 2-6 continuous hyperparameters, expensive models (LeNet, SVM)\n",
    "- Advantage: More sample-efficient than random search\n",
    "\n",
    "**Successive Halving:**\n",
    "- `num_trials`: 20-50\n",
    "- `eta`: 2 or 3 (2 = aggressive pruning, 3 = more conservative)\n",
    "- `r_min`, `r_max`: Based on your model (e.g., 5-20 epochs for FashionMNIST)\n",
    "- Best for: Limited parallel workers (1-4 workers)\n",
    "\n",
    "**ASHA:**\n",
    "- `num_trials`: 50-100+ (scales well with more trials)\n",
    "- `eta`: 2 or 3\n",
    "- `r_min`, `r_max`: Same as Successive Halving\n",
    "- Best for: Many parallel workers (4+ workers), large-scale experiments\n",
    "- Advantage: No worker idle time, scales efficiently\n",
    "\n",
    "### Model-Specific Hyperparameter Ranges:\n",
    "\n",
    "**SGDClassifier:**\n",
    "- `alpha`: `stats.loguniform(1e-6, 1e-1)` - Regularization strength\n",
    "  - Lower = less regularization (may overfit)\n",
    "  - Higher = more regularization (may underfit)\n",
    "- `l1_ratio`: `stats.uniform(0, 1)` - Elastic net mixing\n",
    "  - 0.0 = pure L2 (Ridge regression)\n",
    "  - 1.0 = pure L1 (Lasso, promotes sparsity)\n",
    "  - 0.15 = balanced (good default)\n",
    "\n",
    "**SVMClassifier:**\n",
    "- `C`: `stats.loguniform(1e-2, 1e2)` - Penalty parameter\n",
    "  - Lower = more regularization (simpler model)\n",
    "  - Higher = less regularization (more complex decision boundary)\n",
    "- `gamma`: `stats.loguniform(1e-6, 1e-1)` - RBF kernel coefficient\n",
    "  - Lower = smoother decision boundary (more global)\n",
    "  - Higher = tighter decision boundary (more local)\n",
    "\n",
    "### Performance Tips:\n",
    "\n",
    "1. **Model Selection:**\n",
    "   - LeNet: Best accuracy (~85-90%) but slowest to train\n",
    "   - SoftmaxRegression: Fast baseline (~82-85%)\n",
    "   - SGDClassifier: Fast, good for linear problems (~80-83%)\n",
    "   - SVMClassifier: Good non-linear performance (~83-87%), moderate speed\n",
    "\n",
    "2. **Algorithm Selection:**\n",
    "   - Use **Bayesian BO** for expensive models (LeNet, SVM) with few hyperparameters\n",
    "   - Use **Random Search** as baseline or when search space is simple\n",
    "   - Use **ASHA** when you have many parallel workers\n",
    "   - Use **Successive Halving** when workers are limited\n",
    "\n",
    "3. **Hyperparameter Search Spaces:**\n",
    "   - Always use log-scale for learning rates: `stats.loguniform(1e-4, 1)`\n",
    "   - Always use log-scale for regularization: `stats.loguniform(1e-6, 1e-1)`\n",
    "   - Use linear scale for mixing parameters: `stats.uniform(0, 1)`\n",
    "   - Batch size can be `randint(32, 512)` or powers of 2\n",
    "\n",
    "4. **Multi-Fidelity Settings:**\n",
    "   - Choose r_min to be small enough to quickly identify bad configs (e.g., 5 epochs)\n",
    "   - Choose r_max based on when model converges (e.g., 20 epochs for FashionMNIST)\n",
    "   - η=2 is aggressive (halves configs at each rung), η=3 is more conservative\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Compare Algorithms**: Run all 4 methods on same model and compare:\n",
    "   - Sample efficiency (which finds best config with fewer trials?)\n",
    "   - Time efficiency (which finds good config fastest?)\n",
    "   - Final performance (which achieves best validation accuracy?)\n",
    "\n",
    "2. **Try Different Models**: Test SGD/SVM vs LeNet on FashionMNIST\n",
    "   - How much accuracy do you sacrifice for speed?\n",
    "   - Which hyperparameters matter most?\n",
    "\n",
    "3. **Scale Up**: Apply to larger datasets (CIFAR-10, ImageNet)\n",
    "   - Use ASHA with many parallel workers\n",
    "   - Increase r_max for more complex datasets\n",
    "\n",
    "4. **Combine Methods**: \n",
    "   - BOHB (Bayesian Optimization + Hyperband) = BO with multi-fidelity\n",
    "   - Use BO as searcher instead of RandomSearcher in ASHA\n",
    "\n",
    "5. **Add Constraints**:\n",
    "   - Constrained optimization (e.g., accuracy ≥ 85% AND latency ≤ 100ms)\n",
    "   - Multi-objective optimization (accuracy vs inference speed)\n",
    "\n",
    "6. **Advanced Topics**:\n",
    "   - Transfer learning: Use knowledge from previous HPO runs\n",
    "   - Meta-learning: Learn which configs work well across tasks\n",
    "   - Neural Architecture Search (NAS): Optimize model architecture itself\n",
    "\n",
    "### Common Pitfalls:\n",
    "\n",
    "1. **Using num_epochs with single-fidelity methods:**\n",
    "   - Random Search and Bayesian BO don't use min/max_epochs\n",
    "   - Only multi-fidelity methods (SH, ASHA) use varying epochs\n",
    "\n",
    "2. **Forgetting model-specific hyperparameters:**\n",
    "   - Must include alpha, l1_ratio in config_space for SGD\n",
    "   - Must include C, gamma in config_space for SVM\n",
    "   - Utils.build_model() handles extraction automatically\n",
    "\n",
    "3. **Wrong distribution types:**\n",
    "   - Use `stats.loguniform` for scipy-based BO (not `syne_tune.loguniform`)\n",
    "   - Use `stats.randint` for discrete parameters (not `stats.uniform`)\n",
    "\n",
    "4. **Insufficient random initialization:**\n",
    "   - GP needs diverse observations to build good model\n",
    "   - Use n_random_init ≥ 5 (or 1-2 per hyperparameter)\n",
    "\n",
    "5. **Not training final model properly:**\n",
    "   - For multi-fidelity: use `max_number_of_epochs` for final training\n",
    "   - For single-fidelity: use `args.num_epochs` for final training\n",
    "   - Always pass `best_config` to `Utils.build_model()`\n",
    "\n",
    "### References:\n",
    "\n",
    "- **Bayesian Optimization**: Snoek et al., \"Practical Bayesian Optimization of Machine Learning Algorithms\" (2012)\n",
    "- **Successive Halving**: Jamieson & Talwalkar, \"Non-stochastic Best Arm Identification and Hyperparameter Optimization\" (2016)\n",
    "- **ASHA**: Li et al., \"A System for Massively Parallel Hyperparameter Tuning\" (2018)\n",
    "- **Random Fourier Features**: Rahimi & Recht, \"Random Features for Large-Scale Kernel Machines\" (2007)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
