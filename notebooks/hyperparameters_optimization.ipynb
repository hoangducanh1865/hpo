{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abdedc0",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization (HPO) - Complete Implementation\n",
    "\n",
    "This notebook contains a complete implementation of various HPO algorithms:\n",
    "1. **Basic Random Search** - Simple random sampling of hyperparameters\n",
    "2. **Asynchronous Random Search** - Parallel random search using Syne Tune\n",
    "3. **Successive Halving (SH)** - Synchronous multi-fidelity optimization\n",
    "4. **ASHA (Asynchronous Successive Halving)** - Asynchronous multi-fidelity optimization\n",
    "\n",
    "We use FashionMNIST dataset and train both LeNet and Softmax Regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370d007",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea20468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision tqdm matplotlib scipy numpy\n",
    "# Or\n",
    "'''!pip install -r requirements.txt'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5804eb58",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8813020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from abc import ABC, abstractmethod\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9479af6b",
   "metadata": {},
   "source": [
    "## 3. Configuration Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    '''@staticmethod\n",
    "    def new_parser(name=None):\n",
    "        return argparse.ArgumentParser(prog=name)\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_training_argument(parser):\n",
    "        parser.add_argument(\n",
    "            \"--train_mode\",\n",
    "            type=str,\n",
    "            default=\"asha_hpo\",\n",
    "            choices=[\"hpo\", \"fixed\", \"async_hpo\", \"multi_fidelity_hpo\", \"asha_hpo\"],\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            \"--model_name\", type=str, default=\"lenet\", choices=[\"lenet\", \"softmax\"]\n",
    "        )\n",
    "        parser.add_argument(\"--num_epochs\", type=int, default=1)\n",
    "        parser.add_argument(\"--learning_rate\", type=float, default=0.1)\n",
    "        parser.add_argument(\"--batch_size\", type=int, default=256)\n",
    "        parser.add_argument(\"--num_workers\", type=int, default=2)\n",
    "        parser.add_argument(\"--num_outputs\", type=int, default=10)\n",
    "        parser.add_argument(\"--num_trials\", type=int, default=10)\n",
    "        parser.add_argument(\"--max_wallclock_time\", type=int, default=10 * 60)\n",
    "        parser.add_argument(\"--eta\", type=int, default=2)\n",
    "        parser.add_argument(\"--min_number_of_epochs\", type=int, default=10)\n",
    "        parser.add_argument(\"--max_number_of_epochs\", type=int, default=50)\n",
    "        parser.add_argument(\"--prefact\", type=int, default=1)'''\n",
    "\n",
    "print(f\"Using device: {Config.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28b6b8",
   "metadata": {},
   "source": [
    "## 4. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af538c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression(nn.Module):\n",
    "    \"\"\"Softmax Regression (Multinomial Logistic Regression) model.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_outputs: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(784, num_outputs)  # 28x28 â†’ 784 input features\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "    def loss(self, Y_hat, Y, averaged=True):\n",
    "        Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n",
    "        Y = Y.reshape((-1,))\n",
    "        return F.cross_entropy(Y_hat, Y, reduction=\"mean\" if averaged else \"none\")\n",
    "\n",
    "\n",
    "def init_cnn(module):\n",
    "    \"\"\"Xavier initialization for CNN weights\"\"\"\n",
    "    if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "    \n",
    "    def loss(self, Y_hat, Y, averaged=True):\n",
    "        Y_hat = Y_hat.reshape((-1, Y_hat.shape[-1]))\n",
    "        Y = Y.reshape((-1,))\n",
    "        return F.cross_entropy(Y_hat, Y, reduction=\"mean\" if averaged else \"none\")\n",
    "    \n",
    "    def apply_init(self):\n",
    "        self.apply(init_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48499202",
   "metadata": {},
   "source": [
    "## 5. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df300fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    @staticmethod\n",
    "    def load_fashion_mnist(batch_size):\n",
    "        \"\"\"Load FashionMNIST dataset with train/validation/test split.\"\"\"\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        # Load full datasets\n",
    "        train_dataset = datasets.FashionMNIST(\n",
    "            root=\"./data\", train=True, transform=transform, download=True\n",
    "        )\n",
    "        test_dataset = datasets.FashionMNIST(\n",
    "            root=\"./data\", train=False, transform=transform, download=True\n",
    "        )\n",
    "        \n",
    "        # Split training data into train and validation sets\n",
    "        train_size = int(0.8 * len(train_dataset))  # 80% for training\n",
    "        val_size = len(train_dataset) - train_size  # 20% for validation\n",
    "        \n",
    "        train_subset, val_subset = torch.utils.data.random_split(\n",
    "            train_dataset, [train_size, val_size]\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        return train_loader, val_loader, test_loader\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(y_hat, y):\n",
    "        \"\"\"Compute number of correct predictions.\"\"\"\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        return (preds == y).float().sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_model(args):\n",
    "        if args.model_name == \"softmax\":\n",
    "            return SoftmaxRegression(num_outputs=args.num_outputs)\n",
    "        elif args.model_name == \"lenet\":\n",
    "            model = LeNet(num_classes=args.num_outputs)\n",
    "            model.apply_init()\n",
    "            return model\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                'Model type not supported, use \"softmax\" or \"lenet\" instead'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae76034",
   "metadata": {},
   "source": [
    "## 6. Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader, lr, num_epochs):\n",
    "        self.device = Config.device\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "        self.num_epochs = num_epochs\n",
    "    \n",
    "    def fit(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.train_epoch(epoch)\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        for X, y in tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{self.num_epochs}\"):\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "            y_hat = self.model(X)\n",
    "            loss = self.model.loss(y_hat, y)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "    def evaluate_train(self):\n",
    "        self.model.eval()\n",
    "        total_correct, total_samples = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X, y in self.train_loader:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                y_hat = self.model(X)\n",
    "                total_correct += Utils.accuracy(y_hat, y).item()\n",
    "                total_samples += y.size(0)\n",
    "        \n",
    "        return total_correct / total_samples\n",
    "    \n",
    "    def evaluate_test(self):\n",
    "        self.model.eval()\n",
    "        total_correct, total_samples = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X, y in self.test_loader:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                y_hat = self.model(X)\n",
    "                total_correct += Utils.accuracy(y_hat, y).item()\n",
    "                total_samples += y.size(0)\n",
    "        \n",
    "        return total_correct / total_samples\n",
    "    \n",
    "    def evaluate_val(self):\n",
    "        self.model.eval()\n",
    "        total_correct, total_samples = 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X, y in self.val_loader:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                y_hat = self.model(X)\n",
    "                total_correct += Utils.accuracy(y_hat, y).item()\n",
    "                total_samples += y.size(0)\n",
    "        \n",
    "        return total_correct / total_samples\n",
    "    \n",
    "    def validation_error(self):\n",
    "        return 1.0 - self.evaluate_val()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448b69f1",
   "metadata": {},
   "source": [
    "## 7. HPO Base Classes (Searcher, Scheduler, Tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256abb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPOSeacher(ABC):\n",
    "    @abstractmethod\n",
    "    def sample_config(self) -> dict:\n",
    "        \"\"\"Sample new hyperparameter configuration\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def update(self, config: dict, error: float, additional_info=None):\n",
    "        \"\"\"Update searcher state after trial completion\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class HPOScheduler(ABC):\n",
    "    @abstractmethod\n",
    "    def suggest(self) -> dict:\n",
    "        \"\"\"Suggest next configuration to evaluate\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def update(self, config: dict, error: float, info=None):\n",
    "        \"\"\"Update scheduler after trial completion\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class HPOTuner:\n",
    "    def __init__(self, scheduler: HPOScheduler, objective_fn: callable):\n",
    "        self.scheduler = scheduler\n",
    "        self.objective_fn = objective_fn\n",
    "        self.incumbent = None  # Best performing configuration\n",
    "        self.incumbent_error = None  # Lowest validation error\n",
    "        self.incumbent_trajectory = []  # Lowest validation errors over time\n",
    "        self.cumulative_runtime = []\n",
    "        self.current_runtime = 0\n",
    "        self.records = []\n",
    "    \n",
    "    def run(self, number_of_trials):\n",
    "        for i in range(number_of_trials):\n",
    "            start_time = time.time()\n",
    "            config = self.scheduler.suggest()\n",
    "            print(f\"Trial {i} config: {config}\")\n",
    "            error = self.objective_fn(config)\n",
    "            self.scheduler.update(config, error)\n",
    "            runtime = time.time() - start_time\n",
    "            self.bookkeeping(config, error, runtime)\n",
    "            print(f\"error: {error:.4f} - runtime: {runtime:.2f}\")\n",
    "    \n",
    "    def bookkeeping(self, config: dict, error: float, runtime: float):\n",
    "        \"\"\"Track best configuration and respective performance\"\"\"\n",
    "        self.records.append({\"config\": config, \"error\": error, \"runtime\": runtime})\n",
    "        # Update incumbent\n",
    "        if self.incumbent is None or error < self.incumbent_error:\n",
    "            self.incumbent = config\n",
    "            self.incumbent_error = error\n",
    "        # Track trajectories\n",
    "        self.incumbent_trajectory.append(self.incumbent_error)\n",
    "        self.current_runtime += runtime\n",
    "        self.cumulative_runtime.append(self.current_runtime)\n",
    "    \n",
    "    def get_best_config(self):\n",
    "        return self.incumbent, self.incumbent_error\n",
    "\n",
    "\n",
    "class RandomSearcher(HPOSeacher):\n",
    "    def __init__(self, config_space: dict, initial_config: dict):\n",
    "        self.config_space = config_space\n",
    "        self.initial_config = initial_config\n",
    "    \n",
    "    def sample_config(self) -> dict:\n",
    "        \"\"\"Sample random configuration from config space\"\"\"\n",
    "        if self.initial_config is not None:\n",
    "            result = self.initial_config\n",
    "            self.initial_config = None  # Clear after first use\n",
    "            return result\n",
    "        random_config = {key: domain.rvs() for key, domain in self.config_space.items()}\n",
    "        return random_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b7532",
   "metadata": {},
   "source": [
    "## 8. Basic Scheduler (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c387c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicScheduler(HPOScheduler):\n",
    "    def __init__(self, searcher):\n",
    "        self.searcher = searcher\n",
    "    \n",
    "    def suggest(self) -> dict:\n",
    "        \"\"\"Suggest next configuration\"\"\"\n",
    "        return self.searcher.sample_config()\n",
    "    \n",
    "    def update(self, config: dict, error: float, info=None):\n",
    "        \"\"\"Update searcher with trial results\"\"\"\n",
    "        self.searcher.update(config, error, additional_info=info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1dd2f9",
   "metadata": {},
   "source": [
    "## 9. Multi-Fidelity Scheduler (Synchronous Successive Halving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiFidelityScheduler(HPOScheduler):\n",
    "    def __init__(self, searcher, eta, r_min, r_max, prefact):\n",
    "        self.searcher = searcher\n",
    "        self.eta = eta\n",
    "        self.r_min = r_min\n",
    "        self.r_max = r_max\n",
    "        self.prefact = prefact\n",
    "        self.K = int(np.log(r_max / r_min) / np.log(eta))\n",
    "        self.rung_levels = [r_min * (eta**k) for k in range(self.K + 1)]\n",
    "        if r_max not in self.rung_levels:\n",
    "            self.rung_levels.append(r_max)\n",
    "            self.K += 1\n",
    "        # Bookkeeping\n",
    "        self.observed_error_at_rungs = defaultdict(list)\n",
    "        self.all_observed_error_at_rungs = defaultdict(list)\n",
    "        self.queue = []\n",
    "    \n",
    "    def suggest(self):\n",
    "        if len(self.queue) == 0:\n",
    "            # Start a new round of successive halving\n",
    "            n0 = int(self.prefact * self.eta**self.K)\n",
    "            for _ in range(n0):\n",
    "                config = self.searcher.sample_config()\n",
    "                config[\"num_epochs\"] = self.r_min\n",
    "                self.queue.append(config)\n",
    "        return self.queue.pop()\n",
    "    \n",
    "    def update(self, config: dict, error: float, info=None):\n",
    "        ri = int(config[\"num_epochs\"])\n",
    "        self.searcher.update(config, error, additional_info=info)\n",
    "        self.all_observed_error_at_rungs[ri].append((config, error))\n",
    "        if ri < self.r_max:\n",
    "            self.observed_error_at_rungs[ri].append((config, error))\n",
    "            ki = self.K - self.rung_levels.index(ri)\n",
    "            ni = int(self.prefact * (self.eta**ki))\n",
    "            if len(self.observed_error_at_rungs[ri]) >= ni:\n",
    "                kiplus1 = ki - 1\n",
    "                niplus1 = int(self.prefact * (self.eta**kiplus1))\n",
    "                best_performing_configurations = self.get_top_n_configurations(\n",
    "                    rung_level=ri, n=niplus1\n",
    "                )\n",
    "                riplus1 = self.rung_levels[self.K - kiplus1]\n",
    "                self.queue = [\n",
    "                    dict(config, num_epochs=riplus1)\n",
    "                    for config in best_performing_configurations\n",
    "                ] + self.queue\n",
    "                self.observed_error_at_rungs[ri] = []\n",
    "    \n",
    "    def get_top_n_configurations(self, rung_level, n):\n",
    "        rung = self.observed_error_at_rungs[rung_level]\n",
    "        if not rung:\n",
    "            return []\n",
    "        sorted_rung = sorted(rung, key=lambda x: x[1])\n",
    "        return [x[0] for x in sorted_rung[:n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab9e34c",
   "metadata": {},
   "source": [
    "## 10. ASHA Scheduler (Asynchronous Successive Halving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASHAScheduler(HPOScheduler):\n",
    "    \"\"\"\n",
    "    Asynchronous Successive Halving Algorithm (ASHA)\n",
    "    \n",
    "    Key differences from synchronous SH:\n",
    "    - Promotes configs as soon as enough results are available (not all)\n",
    "    - No synchronization barriers, workers stay busy\n",
    "    - Checks rungs from top to bottom for promotion opportunities\n",
    "    \"\"\"\n",
    "    def __init__(self, searcher, eta, r_min, r_max, prefact=1):\n",
    "        self.searcher = searcher\n",
    "        self.eta = eta\n",
    "        self.r_min = r_min\n",
    "        self.r_max = r_max\n",
    "        self.prefact = prefact\n",
    "        \n",
    "        # Compute rung levels\n",
    "        self.K = int(np.log(r_max / r_min) / np.log(eta))\n",
    "        self.rung_levels = [r_min * (eta**k) for k in range(self.K + 1)]\n",
    "        if r_max not in self.rung_levels:\n",
    "            self.rung_levels.append(r_max)\n",
    "            self.K += 1\n",
    "        \n",
    "        # Track completed trials at each rung\n",
    "        self.completed_trials_at_rungs = defaultdict(list)  # (config, error) pairs\n",
    "        \n",
    "        # Track which configs have been promoted from each rung\n",
    "        self.promoted_configs = defaultdict(set)  # rung -> set of config hashes\n",
    "        \n",
    "        # Track number of configs started at each rung\n",
    "        self.configs_started_at_rung = defaultdict(int)\n",
    "    \n",
    "    def _config_hash(self, config):\n",
    "        \"\"\"Create hashable representation of config (excluding num_epochs)\"\"\"\n",
    "        items = [(k, v) for k, v in sorted(config.items()) if k != 'num_epochs']\n",
    "        return tuple(items)\n",
    "    \n",
    "    def suggest(self):\n",
    "        \"\"\"\n",
    "        ASHA suggest logic:\n",
    "        1. Check rungs from top to bottom for promotion opportunities\n",
    "        2. If found, promote a config to next rung\n",
    "        3. Otherwise, start new config at r_min\n",
    "        \"\"\"\n",
    "        # Check rungs from highest to lowest (excluding r_max)\n",
    "        for i in range(len(self.rung_levels) - 2, -1, -1):\n",
    "            rung = self.rung_levels[i]\n",
    "            next_rung = self.rung_levels[i + 1]\n",
    "            \n",
    "            # Number of configs that should be started at this rung\n",
    "            ki = self.K - i\n",
    "            ni = int(self.prefact * (self.eta ** ki))\n",
    "            \n",
    "            # Check if we have enough completed trials to consider promotion\n",
    "            completed = self.completed_trials_at_rungs[rung]\n",
    "            \n",
    "            if len(completed) >= self.eta:  # Need at least eta completed trials\n",
    "                # Get top 1/eta configs that haven't been promoted yet\n",
    "                sorted_trials = sorted(completed, key=lambda x: x[1])  # Sort by error\n",
    "                \n",
    "                for config, error in sorted_trials:\n",
    "                    config_hash = self._config_hash(config)\n",
    "                    \n",
    "                    # If this config hasn't been promoted from this rung yet\n",
    "                    if config_hash not in self.promoted_configs[rung]:\n",
    "                        # Check if we should promote (top 1/eta fraction)\n",
    "                        top_k = max(1, len(completed) // self.eta)\n",
    "                        top_configs = [self._config_hash(c) for c, _ in sorted_trials[:top_k]]\n",
    "                        \n",
    "                        if config_hash in top_configs:\n",
    "                            # Promote this config\n",
    "                            self.promoted_configs[rung].add(config_hash)\n",
    "                            promoted_config = dict(config)\n",
    "                            promoted_config['num_epochs'] = next_rung\n",
    "                            return promoted_config\n",
    "        \n",
    "        # No promotion opportunity found, start new config at r_min\n",
    "        new_config = self.searcher.sample_config()\n",
    "        new_config['num_epochs'] = self.r_min\n",
    "        self.configs_started_at_rung[self.r_min] += 1\n",
    "        return new_config\n",
    "    \n",
    "    def update(self, config: dict, error: float, info=None):\n",
    "        \"\"\"Record completed trial\"\"\"\n",
    "        ri = int(config['num_epochs'])\n",
    "        \n",
    "        # Update searcher\n",
    "        self.searcher.update(config, error, additional_info=info)\n",
    "        \n",
    "        # Record this completion\n",
    "        self.completed_trials_at_rungs[ri].append((config, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94a8942",
   "metadata": {},
   "source": [
    "## 11. HPO Main Class with All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33626e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPO:\n",
    "    @staticmethod\n",
    "    def hpo_objective_fn(args):\n",
    "        def hpo_objective(config):\n",
    "            lr = config.get(\"learning_rate\", args.learning_rate)\n",
    "            batch_size = config.get(\"batch_size\", args.batch_size)\n",
    "            num_epochs = config.get(\"num_epochs\", args.num_epochs)  # FIX: Read from config\n",
    "            train_loader, val_loader, test_loader = Utils.load_fashion_mnist(batch_size)\n",
    "            model = Utils.build_model(args)\n",
    "            trainer = Trainer(\n",
    "                model,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                test_loader,\n",
    "                lr=lr,\n",
    "                num_epochs=num_epochs,\n",
    "            )\n",
    "            trainer.fit()\n",
    "            val_err = trainer.validation_error()\n",
    "            return val_err\n",
    "        \n",
    "        return hpo_objective\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_search(args, config_space, initial_config):\n",
    "        searcher = RandomSearcher(config_space, initial_config)\n",
    "        scheduler = BasicScheduler(searcher)\n",
    "        objective_fn = HPO.hpo_objective_fn(args)\n",
    "        tuner = HPOTuner(scheduler=scheduler, objective_fn=objective_fn)\n",
    "        print(f\"Starting HPO with {args.num_trials} trials\")\n",
    "        tuner.run(number_of_trials=args.num_trials)\n",
    "        best_config, best_score = tuner.get_best_config()\n",
    "        print(\"\\n\" + \"=\" * 32)\n",
    "        print(f\"HPO Summary:\")\n",
    "        print(f\"Best config: {best_config}\")\n",
    "        print(f\"Best validation error: {best_score:.4f}\")\n",
    "        print(f\"Total runtime: {tuner.current_runtime:.2f}s\")\n",
    "        print(f\"Average time per trial: {tuner.current_runtime/args.num_trials:.2f}s\")\n",
    "        return best_config, best_score, tuner\n",
    "    \n",
    "    @staticmethod\n",
    "    def multi_fidelity_random_search(args, config_space, initial_config):\n",
    "        searcher = RandomSearcher(config_space, initial_config)\n",
    "        scheduler = MultiFidelityScheduler(\n",
    "            searcher=searcher,\n",
    "            eta=args.eta,\n",
    "            r_min=args.min_number_of_epochs,\n",
    "            r_max=args.max_number_of_epochs,\n",
    "            prefact=args.prefact,\n",
    "        )\n",
    "        objective_fn = HPO.hpo_objective_fn(args)\n",
    "        tuner = HPOTuner(scheduler=scheduler, objective_fn=objective_fn)\n",
    "        print(f\"Starting Multi-Fidelity HPO with {args.num_trials} trials\")\n",
    "        tuner.run(number_of_trials=args.num_trials)\n",
    "        best_config, best_score = tuner.get_best_config()\n",
    "        print(\"\\n\" + \"=\" * 32)\n",
    "        print(f\"Multi-Fidelity HPO Summary:\")\n",
    "        print(f\"Best config: {best_config}\")\n",
    "        print(f\"Best validation error: {best_score:.4f}\")\n",
    "        print(f\"Total runtime: {tuner.current_runtime:.2f}s\")\n",
    "        print(f\"Average time per trial: {tuner.current_runtime/args.num_trials:.2f}s\")\n",
    "        return best_config, best_score, tuner\n",
    "    \n",
    "    @staticmethod\n",
    "    def asha_random_search(args, config_space, initial_config):\n",
    "        \"\"\"\n",
    "        Asynchronous Successive Halving Algorithm (ASHA)\n",
    "        \"\"\"\n",
    "        searcher = RandomSearcher(config_space, initial_config)\n",
    "        scheduler = ASHAScheduler(\n",
    "            searcher=searcher,\n",
    "            eta=args.eta,\n",
    "            r_min=args.min_number_of_epochs,\n",
    "            r_max=args.max_number_of_epochs,\n",
    "            prefact=args.prefact,\n",
    "        )\n",
    "        objective_fn = HPO.hpo_objective_fn(args)\n",
    "        tuner = HPOTuner(scheduler=scheduler, objective_fn=objective_fn)\n",
    "        \n",
    "        print(f\"Starting ASHA with {args.num_trials} trials\")\n",
    "        print(f\"Rung levels: {scheduler.rung_levels}\")\n",
    "        print(f\"eta={args.eta}, r_min={args.min_number_of_epochs}, r_max={args.max_number_of_epochs}\")\n",
    "        \n",
    "        tuner.run(number_of_trials=args.num_trials)\n",
    "        best_config, best_score = tuner.get_best_config()\n",
    "        \n",
    "        # Print rung statistics\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ASHA Rung Statistics:\")\n",
    "        for rung in scheduler.rung_levels:\n",
    "            n_completed = len(scheduler.completed_trials_at_rungs[rung])\n",
    "            n_promoted = len(scheduler.promoted_configs[rung])\n",
    "            print(f\"  Rung {rung:3d}: {n_completed:3d} completed, {n_promoted:3d} promoted\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"ASHA HPO Summary:\")\n",
    "        print(f\"Best config: {best_config}\")\n",
    "        print(f\"Best validation error: {best_score:.4f}\")\n",
    "        print(f\"Total runtime: {tuner.current_runtime:.2f}s\")\n",
    "        print(f\"Average time per trial: {tuner.current_runtime/args.num_trials:.2f}s\")\n",
    "        \n",
    "        return best_config, best_score, tuner\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_hpo_progress(tuner, save_path=None):\n",
    "        \"\"\"Plot HPO progress over time\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Plot incumbent error vs trials\n",
    "        ax1.plot(range(len(tuner.incumbent_trajectory)), tuner.incumbent_trajectory)\n",
    "        ax1.set_xlabel(\"Trial\")\n",
    "        ax1.set_ylabel(\"Best Validation Error\")\n",
    "        ax1.set_title(\"HPO Progress: Best Error vs Trials\")\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Plot incumbent error vs cumulative runtime\n",
    "        ax2.plot(tuner.cumulative_runtime, tuner.incumbent_trajectory)\n",
    "        ax2.set_xlabel(\"Cumulative Runtime (s)\")\n",
    "        ax2.set_ylabel(\"Best Validation Error\")\n",
    "        ax2.set_title(\"HPO Progress: Best Error vs Time\")\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f43c5",
   "metadata": {},
   "source": [
    "## 12. Create Arguments Class for Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df8123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    \"\"\"Simple arguments class for notebook usage\"\"\"\n",
    "    def __init__(self):\n",
    "        self.model_name = \"lenet\"\n",
    "        self.num_epochs = 10\n",
    "        self.learning_rate = 0.1\n",
    "        self.batch_size = 256\n",
    "        self.num_workers = 2\n",
    "        self.num_outputs = 10\n",
    "        self.num_trials = 20\n",
    "        self.max_wallclock_time = 600\n",
    "        self.eta = 2\n",
    "        self.min_number_of_epochs = 5\n",
    "        self.max_number_of_epochs = 20\n",
    "        self.prefact = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479396f1",
   "metadata": {},
   "source": [
    "## 13. Example 1: Basic Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79010dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure arguments\n",
    "args = Args()\n",
    "\n",
    "# Define search space\n",
    "config_space = {\n",
    "    \"learning_rate\": stats.loguniform(1e-4, 1),\n",
    "    \"batch_size\": stats.randint(32, 512),\n",
    "}\n",
    "\n",
    "initial_config = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"batch_size\": 256,\n",
    "}\n",
    "\n",
    "# Run basic random search\n",
    "best_config, best_score, tuner = HPO.random_search(\n",
    "    args, config_space=config_space, initial_config=initial_config\n",
    ")\n",
    "\n",
    "# Plot progress\n",
    "HPO.plot_hpo_progress(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e1c59",
   "metadata": {},
   "source": [
    "## 14. Example 2: Successive Halving (Multi-Fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure arguments for multi-fidelity\n",
    "args = Args()\n",
    "args.model_name = \"lenet\"\n",
    "args.num_trials = 10\n",
    "args.eta = 2\n",
    "args.min_number_of_epochs = 5\n",
    "args.max_number_of_epochs = 20\n",
    "args.prefact = 1\n",
    "\n",
    "# Define search space (same as before)\n",
    "config_space = {\n",
    "    \"learning_rate\": stats.loguniform(1e-4, 1),\n",
    "    \"batch_size\": stats.randint(32, 512),\n",
    "}\n",
    "\n",
    "initial_config = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"batch_size\": 256,\n",
    "}\n",
    "\n",
    "# Run multi-fidelity HPO (Successive Halving)\n",
    "best_config, best_score, tuner = HPO.multi_fidelity_random_search(\n",
    "    args, config_space=config_space, initial_config=initial_config\n",
    ")\n",
    "\n",
    "# Plot progress\n",
    "HPO.plot_hpo_progress(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0584529",
   "metadata": {},
   "source": [
    "## 15. Example 3: ASHA (Asynchronous Successive Halving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226106af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure arguments for ASHA\n",
    "args = Args()\n",
    "args.model_name = \"lenet\"\n",
    "args.num_trials = 20\n",
    "args.eta = 2\n",
    "args.min_number_of_epochs = 5\n",
    "args.max_number_of_epochs = 20\n",
    "args.prefact = 1\n",
    "\n",
    "# Define search space\n",
    "config_space = {\n",
    "    \"learning_rate\": stats.loguniform(1e-4, 1),\n",
    "    \"batch_size\": stats.randint(32, 512),\n",
    "}\n",
    "\n",
    "initial_config = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"batch_size\": 256,\n",
    "}\n",
    "\n",
    "# Run ASHA\n",
    "best_config, best_score, tuner = HPO.asha_random_search(\n",
    "    args, config_space=config_space, initial_config=initial_config\n",
    ")\n",
    "\n",
    "# Plot progress\n",
    "HPO.plot_hpo_progress(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed4f865",
   "metadata": {},
   "source": [
    "## 16. Train Final Model with Best Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ad0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best config from ASHA to train a final model\n",
    "print(f\"\\nTraining final model with best config: {best_config}\")\n",
    "\n",
    "train_loader, val_loader, test_loader = Utils.load_fashion_mnist(\n",
    "    best_config[\"batch_size\"]\n",
    ")\n",
    "model = Utils.build_model(args)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=best_config[\"learning_rate\"],\n",
    "    num_epochs=args.max_number_of_epochs,  # Train with full epochs\n",
    ")\n",
    "\n",
    "trainer.fit()\n",
    "\n",
    "train_acc = trainer.evaluate_train()\n",
    "val_acc = 1.0 - trainer.validation_error()\n",
    "test_acc = trainer.evaluate_test()\n",
    "\n",
    "print(f\"\\nFinal Results with ASHA-tuned hyperparameters:\")\n",
    "print(f\"Train accuracy: {train_acc:.4f}\")\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba96be60",
   "metadata": {},
   "source": [
    "## 17. Summary and Key Takeaways\n",
    "\n",
    "### HPO Algorithms Comparison:\n",
    "\n",
    "| Algorithm | Synchronization | Multi-Fidelity | Best Use Case |\n",
    "|-----------|----------------|----------------|---------------|\n",
    "| **Random Search** | Sequential | No | Small search spaces, baseline |\n",
    "| **Successive Halving** | Synchronous | Yes | Limited parallel workers |\n",
    "| **ASHA** | Asynchronous | Yes | Many parallel workers, large-scale |\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Resource**: In this implementation, the resource is `num_epochs` (number of training epochs)\n",
    "2. **Rung**: A level in multi-fidelity optimization where configs are evaluated with the same resource\n",
    "3. **eta (Î·)**: Reduction factor - determines how many configs to keep at each rung (keep 1/Î·)\n",
    "4. **r_min**: Minimum resource (lowest number of epochs)\n",
    "5. **r_max**: Maximum resource (highest number of epochs)\n",
    "\n",
    "### ASHA Advantages:\n",
    "\n",
    "- **No worker idle time**: Workers don't wait for synchronization\n",
    "- **Better resource utilization**: Configs promoted as soon as possible\n",
    "- **Scalable**: Works well with many parallel workers\n",
    "- **Early stopping**: Poor configs stopped early, saving computation\n",
    "\n",
    "### Recommended Settings:\n",
    "\n",
    "For your default config (eta=2, r_min=10, r_max=50):\n",
    "- **nâ‚€ = 4** configs at first rung (synchronous SH)\n",
    "- **Recommended trials for ASHA**: 20-30 trials\n",
    "- **Rungs**: [10, 20, 40, 50] epochs\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Experiment with different `eta` values (2, 3, 4)\n",
    "2. Try different search spaces (add dropout, weight decay)\n",
    "3. Test with different models (ResNet, VGG, etc.)\n",
    "4. Scale to larger datasets (CIFAR-10, ImageNet)\n",
    "5. Integrate Bayesian optimization for smarter search"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
